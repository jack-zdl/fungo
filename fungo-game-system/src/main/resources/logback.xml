<?xml version="1.0" encoding="UTF-8" ?>

<!-- 级别从高到低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL -->
<!-- 日志输出规则 根据当前ROOT 级别，日志输出时，级别高于root默认的级别时 会输出 -->
<!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志 -->
<!-- scan 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 -->
<!-- scanPeriod 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 -->
<!-- debug 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration scan="true" scanPeriod="60 seconds" debug="false">

    <!-- 动态日志级别 -->
    <jmxConfigurator/>

    <!-- 定义日志文件 输出位置 -->
    <property name="log.home_dir" value="./system_logs/"/>
    <!-- 日志最大的历史 30天 -->
    <property name="log.maxHistory" value="30"/>

    <property name="log.level" value="info"/>


    <!-- ConsoleAppender 控制台输出日志 -->
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>
                <!-- 设置日志输出格式 -->
                %d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger - %msg%n
            </pattern>
        </encoder>
    </appender>


    <!-- ERROR级别日志 -->
    <!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 RollingFileAppender -->
<!--    <appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">-->
<!--        &lt;!&ndash; 过滤器，只记录WARN级别的日志 &ndash;&gt;-->
<!--        &lt;!&ndash; 果日志级别等于配置级别，过滤器会根据onMath 和 onMismatch接收或拒绝日志。 &ndash;&gt;-->
<!--        <filter class="ch.qos.logback.classic.filter.LevelFilter">-->
<!--            &lt;!&ndash; 设置过滤级别 &ndash;&gt;-->
<!--            <level>ERROR</level>-->
<!--            &lt;!&ndash; 用于配置符合过滤条件的操作 &ndash;&gt;-->
<!--            <onMatch>ACCEPT</onMatch>-->
<!--            &lt;!&ndash; 用于配置不符合过滤条件的操作 &ndash;&gt;-->
<!--            <onMismatch>DENY</onMismatch>-->
<!--        </filter>-->
<!--        &lt;!&ndash; 最常用的滚动策略，它根据时间来制定滚动策略.既负责滚动也负责触发滚动 &ndash;&gt;-->
<!--        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">-->
<!--            &lt;!&ndash;日志输出位置 可以是相对和绝对路径 &ndash;&gt;-->
<!--            <fileNamePattern>-->
<!--                ${log.home_dir}/error/%d{yyyy-MM-dd}/fungaGame-error-%i.log-->
<!--            </fileNamePattern>-->
<!--            &lt;!&ndash; 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件假设设置每个月滚动，且<maxHistory>是6， 则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除 &ndash;&gt;-->
<!--            <maxHistory>${log.maxHistory}</maxHistory>-->
<!--            <TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">-->
<!--                &lt;!&ndash; 单个log文件超过该大小就会重新建一个log文件 &ndash;&gt;-->
<!--                    <MaxFileSize>10MB</MaxFileSize>-->
<!--                </TimeBasedFileNamingAndTriggeringPolicy>-->
<!--            </rollingPolicy>-->
<!--            <encoder>-->
<!--                <pattern>-->
<!--                    &lt;!&ndash; 设置日志输出格式 &ndash;&gt;-->
<!--                %d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger - %msg%n-->
<!--            </pattern>-->
<!--        </encoder>-->
<!--    </appender>-->


    <!-- WARN级别日志 appender -->
    <appender name="WARN" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤器，只记录WARN级别的日志 -->
        <!-- 果日志级别等于配置级别，过滤器会根据onMath 和 onMismatch接收或拒绝日志。 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 设置过滤级别 -->
            <level>WARN</level>
            <!-- 用于配置符合过滤条件的操作 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 用于配置不符合过滤条件的操作 -->
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!--日志输出位置 可相对、和绝对路径 -->
            <fileNamePattern>${log.home_dir}/warn/%d{yyyy-MM-dd}/fungaGame-warn-%i.log</fileNamePattern>
            <maxHistory>${log.maxHistory}</maxHistory>
            <TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </TimeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger - %msg%n</pattern>
        </encoder>
    </appender>


    <!-- INFO级别日志 appender -->
    <appender name="INFO" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${log.home_dir}/info/%d{yyyy-MM-dd}/fungaGame-info-%i.log</fileNamePattern>
            <maxHistory>${log.maxHistory}</maxHistory>
            <TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </TimeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger - %msg%n</pattern>
        </encoder>
    </appender>


    <!-- DEBUG级别日志 appender -->
    <appender name="DEBUG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>DEBUG</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${log.home_dir}/debug/%d{yyyy-MM-dd}/fungaGame-debug-%i.log</fileNamePattern>
            <maxHistory>${log.maxHistory}</maxHistory>
            <TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </TimeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger - %msg%n</pattern>
        </encoder>
    </appender>


    <!-- TRACE级别日志 appender -->
    <appender name="TRACE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>TRACE</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${log.home_dir}/trace/%d{yyyy-MM-dd}/fungaGame-trace-%i.log</fileNamePattern>
            <maxHistory>${log.maxHistory}</maxHistory>
            <TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>10MB</MaxFileSize>
            </TimeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger - %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <filter class="ch.qos.logback.classic.filter.LevelFilter"><!-- 只打印错误日志 -->
            <!-- 设置过滤级别 -->
            <level>INFO</level>
            <!-- 用于配置符合过滤条件的操作 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 用于配置不符合过滤条件的操作 -->
            <onMismatch>DENY</onMismatch>
        </filter>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
            <charset>utf8</charset>
        </encoder>
<!--        <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder" >-->
<!--            <customFields>{"appname":"webdemo"}</customFields>-->
<!--            <includeMdc>true</includeMdc>-->
<!--            <includeContext>true</includeContext>-->
<!--            <throwableConverter class="net.logstash.logback.stacktrace.ShortenedThrowableConverter">-->
<!--                <maxDepthPerThrowable>30</maxDepthPerThrowable>-->
<!--                <rootCauseFirst>true</rootCauseFirst>-->
<!--            </throwableConverter>-->
<!--        </encoder>-->
        <topic>kafkaLog</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.BlockingDeliveryStrategy">
            <!-- wait indefinitely until the kafka producer was able to send the message -->
            <timeout>0</timeout>
        </deliveryStrategy>
        <producerConfig>bootstrap.servers=47.92.146.75:9020</producerConfig>
        <!-- 如果kafka不可用则输出到控制台 -->
        <appender-ref ref="WARN"/>
         don't wait for a broker to ack the reception of a batch.
        <producerConfig>acks=0</producerConfig>
        <!-- wait up to 1000ms and collect log messages before sending them as a batch -->
        <producerConfig>linger.ms=1000</producerConfig>
        <!-- even if the producer buffer runs full, do not block the application but start to drop messages -->
        <producerConfig>max.block.ms=0</producerConfig>
<!--        <producerConfig>client.id=${HOSTNAME}-${CONTEXT_NAME}-logback-relaxed</producerConfig>-->
    </appender>

    <!-- 指定项目中的logger -->
<!--    <logger name="com.fungo.system.service.impl" level="ERROR" >-->
<!--        <appender-ref ref="kafka" />-->
<!--    </logger>-->
    <root level="ERROR">
        <appender-ref ref="kafkaAppender"/>
    </root>
    <!-- root级别   INFO -->
<!--    <root>-->
<!--        &lt;!&ndash; 打印INFO级别日志及以上级别日志 &ndash;&gt;-->
<!--        <level value="${log.level}"/>-->

<!--        &lt;!&ndash; 控制台输出 &ndash;&gt;-->
<!--        <appender-ref ref="console"/>-->

<!--        &lt;!&ndash; 文件输出 &ndash;&gt;-->
<!--&lt;!&ndash;        <appender-ref ref="ERROR">&ndash;&gt;-->
<!--&lt;!&ndash;        </appender-ref>&ndash;&gt;-->
<!--&lt;!&ndash;        <appender-ref ref="kafka">&ndash;&gt;-->
<!--&lt;!&ndash;        </appender-ref>&ndash;&gt;-->
<!--        <appender-ref ref="kafkaAppender"/>-->
<!--        <appender-ref ref="WARN"/>-->
<!--        <appender-ref ref="INFO"/>-->

<!--        <appender-ref ref="DEBUG"/>-->
<!--        <appender-ref ref="TRACE"/>-->

<!--    </root>-->
</configuration>
